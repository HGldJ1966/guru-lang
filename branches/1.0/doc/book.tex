\documentclass{book}[12pt]
\usepackage{times}
\usepackage{url}
\usepackage{fullpage}

\newcommand{\guru}[0]{\textsc{Guru}}

\begin{document}

\title{Verified Programming in \guru}

\author{Aaron Stump \\
Computer Science \\
The University of Iowa \\
Iowa City, Iowa, USA
}

\maketitle

\tableofcontents

\chapter{Introduction}
\label{ch1}

\section{Verified Programming}

Software errors are estimated to cost the U.S. economy \$60 billion a
year, and they contribute to computer security vulnerabilities which
end up costing U.S. companies a similar amount~\cite{nist02,fbi05}.
Possibly buggy software cannot be used for safety critical systems
like biomedical implants, nuclear reactors, airplanes, and utilities
infrastructure, at least not without costly backup mechanisms to
handle the case of software failure.  These reasons alone are certainly
enough to motivate our efforts to eliminate the possibility of bugs 
from our software.

But there is another reason to seek to create software that is
absolutely guaranteed to be free from errors: the basic desire we have
as computer scientists to create excellent software.  How
dissatisfying it is to write code that we know we cannot truly trust!
Even if we test it heavily, it may still fail.  It has famously been
said that testing can establish the presence of bugs, but not their
absence: we might always have missed that one input scenario that
breaks the system.  For anyone who loves the construction of elaborate
virtual edifices and intricate logical structures, verification has to
be an addicting activity.

Indeed it is.  The approach we will follow in this book is to
construct, along with our software, proofs that the software is
correct.  These proofs are formal artifacts, just like programs.  The
compiler checks that they are completely logically sound -- no missing
cases or incorrect inferences, for example -- when it compiles our
code.  If the proofs check, then we can be much more confident that
our software is correct.  Of course, it is always possible there is a
bug in the compiler (or in the operating system or standard libraries
the compiler relies on), but assuming there is not, then we know our
code truly has the properties we have proved it has.  No matter what
inputs we throw at it, it will always behave as our theorems promise
us it will.

Constructing programs and proofs together is, quite possibly, the most
complex engineering activity known to humankind.  It can be quite
challenging, and at times frustrating, for example when proofs fail to
go through not because the code is buggy, but because the property one
wishes to prove must be carefully rephrased.  But building verified
software is extremely rewarding.  The mental effort required is very
stimulating, even if we will never again write a line of
machine-checked proof.  Furthermore, even if we verify only fairly
modest properties of a piece of code -- and any verification is
necessarily incomplete, since can never exhaust the things we might
potentially wish to prove about a piece of code -- it is my experience
that even lightly verified code tends to work much, much better right
from the start than unverified code.  

\section{Functional Programming}

Mainstream programming languages like \textsc{Java} and \textsc{C++},
while powerful and effective for many applications, pose problems for
program verification.  This is for several reasons.  First, these are
large languages, with many different features.  They also come with
large standard libraries, which have to be accounted for in order to
verify programs that use them.  Also, they are based on programming
paradigms for which practically effective formal reasoning principles
are still being worked out.  For example, reasoning about programs
even with such a familiar and seemingly simple feature as
\emph{mutable state} is not at all trivial.  Mutable state means that
the value stored in a variable can be changed later.  The reader
perhaps has never even dreamed there could be languages where this is
not the case (where once a variable is assigned a value, that value
cannot be changed).  We will study such a language in this chapter.
Object-orientation of programs creates additional difficulties for
formal reasoning.

Where object-oriented languages are designed around the idea of an
object, functional programming languages are designed around the idea
of a function.  Modern examples with significant user communities and
tool support include \textsc{Caml} (pronounced ``camel'',
http://caml.inria.fr/) and \textsc{Haskell} (http://www.haskell.org/).
\textsc{Haskell} is particularly interesting for our purposes, because
the language is \emph{pure}: there is no mutable state of any kind.
Indeed, \textsc{Haskell} programs have a remarkable property: any
expression in a program is guaranteed to evaluate in exactly the same
way every time it is evaluated.  This property fails magnificently in
mainstream languages, where expressions like
``\texttt{gettimeofday()}'' are, of course, intended to evaluate
differently each time they are called.  Reasoning about impure
programs requires reasoning about the state they depend on.  Reasoning
about pure programs does not, and is thus simpler.  Nevertheless, pure
languages like \textsc{Haskell} do have a way of providing functions
like ``\texttt{gettimeofday()}''.  We will consider ways to provide
such functionality in a pure language in a later chapter.

\section{What is \guru?}

\guru\ is a pure functional programming language, which is similar in
some ways to Caml and Haskell.  But \guru\ also contains a language
for writing formal proofs demonstrating the properties of programs.
So there are really two languages: the language of programs, and the
language of proofs.  When the compiler checks a program, it computes a
type for it, just as compilers for other languages like \textsc{Java}
do.  But in \guru, such types can be significantly richer than in
mainstream or even most research programming languages.  These types
are called \emph{dependent types}, and they can express non-trivial
semantic properties of data and functions.  Analogously, when the
compiler checks a proof, it computes a formula for it, namely the
formula the proof proves.  So we really have four kinds of expressions
in \guru: programs (which we also call \emph{terms}) and their types;
proofs and their formulas.

\guru\ is inspired largely by the \textsc{Coq} theorem prover, used
for formalized mathematics and theoretical computer science, as well
as program verification~\cite{coq}.  Like \textsc{Coq}, \guru\ has
syntax for both proofs and programs, and supports dependent types.
\guru\ does not have as complex forms of polymorphism and dependent
types as \textsc{Coq} does. But \guru\ supports some features that are
difficult or impossible for \textsc{Coq} to support, which are useful
for practical program verification.  In \textsc{Coq}, the compiler
must be able to confirm that all programs are \emph{uniformly
terminating}: they must terminate on all possible inputs.  We know
from basic recursion theory or theoretical computer science that this
means there are some programs which really do terminate on all inputs
that the compiler will not be able to confirm do so.  Furthermore,
some programs, like web servers or operating systems, are not intended
to terminate.  So that is a significant limitation.  Other features
\guru\ has that \textsc{Coq} lacks include support for functional
modeling of non-functional constructs like destructive updates of data
structures and arrays; and better support for proving properties of
dependently typed functions.

So \guru\ is a verified programming language.  In this book, we will
also refer to the open-source project consisting of a compiler for
\guru\ code, the standard library of \guru\ code, and other materials
as ``\guru'' (or ``the \guru\ project'').  Finally, the compiler for
\guru\ code, which includes a type- and proof-checker, as well as an
interpreter, is called \texttt{guru}.  We will work with version 1.0
of \guru.

\section{Installing \guru}

This book assumes you will be using \guru\ on a Linux computer, but it
does not assume much familiarity with Linux.  To install \guru, first
start a shell. Then run the folllowing \textsc{Subversion} command:

\begin{verbatim}
svn checkout http://guru-lang.googlecode.com/svn/branches/1.0 guru-lang
\end{verbatim}

\noindent This will create a subdirectory called \texttt{guru-lang} of
your home directory.  This directory contains the \textsc{Java} source
code for \guru\ version 1.0 itself (\texttt{guru-lang/guru}), the
standard library written in \guru\ (\texttt{guru-lang/lib}), this
book's source code (\texttt{guru-lang/doc}), and a number of tests
written in \guru\ (\texttt{guru-lang/tests}).  A few things in the
distribution currently depend on its being called \texttt{guru-lang},
and residing in your home directory.

Before you can use \guru, you must compile it.  To do this, in your
shell, you should change to the \texttt{guru-lang} directory.  Then
run the command \texttt{make} from the shell.  This will invoke the
\textsc{Java} compiler to compile the \textsc{Java} source files in
\texttt{guru-lang/guru}.  After this is complete, you can run
\texttt{guru-lang/bin/guru} from the shell to process \guru\ source
files.  This will be further explained in Section~\ref{ch2:natguru}
below.

\section{The Structure of This Book}

We begin with \emph{monomorphic} functional programming in \guru.
Monomorphic means that code operates only over data of specific known
types. We will see further how to write proofs demonstrating that such
functions satisfy properties we might be interested in verifying.
Next, we consider \emph{polymorphic}, or generic, programming, where
code may operate generically over data of any type, not known in
advance by the code.  We again see how to write proofs showing that
such functions have the properties we might be interested in.  The
next step is \emph{dependently typed} programming.  Here, the types of
data and functions themselves capture the properties we are interested
in verifying.  There is no separate proof to write for such
properties, rather the program contains proofs to help the type
checker check that the code really meets its specification.  We will
then see how to write additional proofs about dependently typed
programs. Finally, we see how non-functional constructs like updatable
arrays are handled in \guru\ via \emph{functional modeling}.

\section{Acknowledgments}

The following people, listed alphabetically, have assisted me with
with either the theory or implementation of \guru\ or its standard
library: Morgan Deters, Henry Li, Todd Schiller, Timothy Simpson,
Daniel Tratos, and Edwin Westbrook.  This research has been partially
supported by the National Science Foundation under grant CCF-0448275.

\chapter{Monomorphic Functional Programming}

Like most other functional programming languages, the heart of the
\guru's programming language is very compact and simple: we can define
inductive datatype, write (recursive) functions, decompose inductive
data using a simple pattern-matching construct, and apply (aka, call)
functions.  That is essentially it.  Recursion is such a powerful idea
that even with such a simple core, we can write arbitrarily rich and
complex programs.  We will consider first inductive datatypes, then
non-recursive functions, pattern matching, and finally recursive
functions.  When we turn to polymorphic and especially dependently
typed programming in later chapters, we will have to revisit all these
concepts (inductive types, recursive functions, pattern matching, and
function applications), which become richer in those richer
programming settings.  So the syntax in this chapter will be enriched
in later chapters.

\section{Inductive Datatypes}

At the heart of functional programming languages like \textsc{Caml}
and \textsc{Haskell} -- but not functional languages like
\textsc{LISP} and its dialects (e.g., \textsc{Scheme}) -- are
user-declared inductive datatypes.  An inductive datatype consists of
data which are incrementally and uniquely built up using a finite set
of operations, called the \emph{constructors} of the datatype.
Incrementally built up means that bigger data are obtained by gradual
augmentation from smaller data.  Uniquely means that the same piece of
data cannot be built up in two different ways.  Let us consider a
basic example.

\subsection{Unary natural numbers}

The natural numbers are the numbers $0,1,2,\ldots$.  We typically
write numbers in decimal notation.  Unary notation is much simpler.
Essentially, a number like 5 is represented by making 5 marks, for
example like this:

\[ |\ |\ |\ |\ | \]

\noindent A few questions arise.  How do we represent zero?  By zero
marks?  It is then hard to tell if we have written zero or just not
written anything at all.  We will $Z$ for zero.  Also, how does this
fit the pattern of an inductive datatype?  That is, how are bigger
pieces of data (i.e., bigger numbers) obtained incrementally and
uniquely from smaller ones?  One answer is that a number like five can
be viewed as built up from its \emph{predecessor} 4 by the
\emph{successor} operation, which we will write $S$.  The successor
operation just adds one to a natural number.  In this book, we will
write the \emph{application} of a function $f$ to an input argument
$x$ as $f\ x$ or $(f\ x)$.  This is in contrast to other common
mathematical notation, where we write $f(x)$ for function application.
So the five-fold application of the successor operation to zero,
representing the number 5, is written this way:

\[ (S\ (S\ (S\ (S\ (S\ Z))))) \]

Every natural number is either $Z$ or can be built from $Z$ by
applying the successor operation a finite number of times.
Furthermore, every natural number is uniquely built that way.  This
would not be true if in addition to $Z$ and $S$, we included an
operation $P$ for predecessor.  In that case, there would be an
infinite number of ways to build every number.  For example, $Z$ could
be built using just $Z$, or also in these ways (and others):

\[ 
\begin{array}{l}
(S\ (P\ Z)) \\
(S\ (S\ (P\ (P\ Z)))) \\
(S\ (S\ (S\ (P\ (P\ (P\ Z)))))) \\
\ldots
\end{array}
\]

\noindent The operations $Z$ and $S$ are the \emph{constructors} of
the natural number datatype.

The simplicity of unary natural numbers comes at a price.  The
representation of a number in unary is exponentially larger than its
representation in decimal notation.  For example, it takes very many
slash marks or applications of $S$ to write $100$ (decimal notation)
in unary.  In contrast, it only takes 3 digits in decimal.  On the
other hand, it is much easier to reason about unary natural numbers
than binary or decimal numbers, and also easier to write basic
programs like addition.  So we begin with unary natural numbers.

\subsection{Unary natural numbers in \guru}
\label{ch2:natguru}

\guru's standard library includes a definition of unary natural
numbers, and definitions of standard arithmetic functions operating on
them.  To play with these, first start up a text editor, and create a
new file called \texttt{test.g}.  Start this file with the following
text:

\begin{verbatim}
Include "guru-lang/lib/plus.g".
\end{verbatim}

\noindent This \texttt{Include}-command will tell \texttt{guru} to
include the file \texttt{plus.g} from the standard library.  Then
include the following additional command:

\begin{verbatim}
Interpret (plus (S (S Z)) (S (S Z))).
\end{verbatim}

\noindent This \texttt{Interpret}-command tells \guru\ to run its
interpreter on the given expression.  The interpreter will evaluate
the expression to a value, and then print the value.  This expression
is an application of the function \texttt{plus}, which we will see how
to define shortly, to 2 and 2, written in unary.  Naturally, we expect
this will evaluate to 4, written in unary.

To run \texttt{guru} on your \texttt{test.g} file, first make sure
you have saved your changes to it.  Then, start a shell, and run
the command

\begin{verbatim}
guru-lang/bin/guru test.g
\end{verbatim}

\noindent This runs the \texttt{guru} tool on your file.  You should
see it print out the expected result of adding 2 and 2 in unary:

\begin{verbatim}
(S (S (S (S Z))))
\end{verbatim}

The declaration of the unary natural numbers is in
\texttt{guru-lang/lib/nat.g}, which is included by the file
\texttt{plus.g} which we have included here.  If you look in
\texttt{nat.g}, you will find at the top:

\begin{verbatim}
Inductive nat : type :=
  Z : nat
| S : Fun(x:nat).nat.
\end{verbatim}

\noindent This is an \texttt{Inductive}-command.  It instructs \guru\
to declare the new inductive datatype \texttt{nat}.  The ``\texttt{nat
: type}'' on the first line of the declaration just tells \guru\ that
\texttt{nat} is a type.  We will see other examples later which use
more complicated declarations than just ``: \texttt{type}''.  In more
detail, ``\texttt{nat} : \texttt{type}'' means that \texttt{type} is
the \emph{classifier} of \texttt{nat}.  The concept of classifier is
central to \guru.  For example, the next two lines declare the
classifiers for \texttt{Z} (zero) and \texttt{S} (successor).  So what
is a classifier?  In \guru, some expressions are classifiers for
others.  For example, \texttt{type} is the classifier for types.
Following the processing of this \texttt{Inductive}-command, we will
also have that \texttt{nat} is the classifier for unary natural
numbers encoded with \texttt{Z} and \texttt{S}.  The classifier for
\texttt{S} states that it is a function (indicated with \texttt{Fun})
that takes in an input called \texttt{x} that is a \texttt{nat}, and
then produces a \texttt{nat}.  Generally speaking, classifiers
partition expressions into sets of expressions that have certain
similar properties.  Every expression in \textsc{Guru} has exactly one
classifier.

An additional simple piece of terminology is useful.  The constructor
\texttt{Z} returns a \texttt{nat} as output without being given any
\texttt{nat} (or any other data) as input.  In general, a constructor
of a type \texttt{T} which has the property that it returns a
\texttt{T} as output without requiring a \texttt{T} as input is called
a \emph{base} constructor.  In contrast, \texttt{S} does require a
\texttt{nat} as input.  In general, a constructor of a type \texttt{T}
which requires a \texttt{T} as input is called a \emph{recursive}
constructor.

We should note finally that \guru\ does not provide decimal notation
for unary natural numbers.  Indeed, \guru\ currently does not provide
special syntax for describing any data.  There are no built-in
datatypes in \guru: all data are inductive, constructed by applying
constructors (like \texttt{S} and \texttt{Z}) to smaller data.

\section{Non-recursive Functions}

Suppose we want to define a doubling function, based on the
\texttt{plus} function we used before.  We have not seen how to define
\texttt{plus} yet, since it requires recursion and pattern matching.
But of course, we can write a function which calls \texttt{plus},
even if we do not know how \texttt{plus} is written.  The doubling
function can be written like this:

\begin{verbatim}
fun(x:nat).(plus x x)
\end{verbatim}

\noindent Let us examine this piece of code.  First, ``\texttt{fun}''
is the keyword which begins a function, also called a
\texttt{fun}-term.  After this keyword come the arguments to the
function, in parentheses.  In this case, there is just one argument,
\texttt{x}.  Arguments must be listed with their types (with a colon
in between).  In this case, the type is \texttt{nat}.  After the
arguments we have a period, and then \emph{body} of the
\texttt{fun}-term.  The body just gives the code to compute the value
returned by the function.  In this case, the value returned is just
the result of the application of \texttt{plus} to \texttt{x} and
\texttt{x}, for which the notation, as we have already seen, is
\texttt{(plus x x)}.

To use this function in \guru, try the following.  In your home
directory, create a file \texttt{test.g}, and begin it with

\begin{verbatim}
Include "guru-lang/lib/plus.g".
\end{verbatim}

\noindent As for the example in Section~\ref{ch2:natguru} above,
this includes the definitions of \texttt{nat} and \texttt{plus}.
Next write:

\begin{verbatim}
Interpret (fun(x:nat).(plus x x) (S (S Z))).
\end{verbatim}

\noindent Save this file, and then from your home directory run
\guru\ on your file:

\begin{verbatim}
guru-lang/bin/guru test.g
\end{verbatim}

\noindent You should see it print out the expected result of doubling
2, in unary:

\begin{verbatim}
(S (S (S (S Z))))
\end{verbatim}

\noindent This example illustrates the fact that
\texttt{fun(x:nat).(plus x x)} is really a function, just like
\texttt{plus}.  Just as we can apply \texttt{plus} to arguments
\texttt{x} and \texttt{y} by writing \texttt{(plus x x)}, we can also
apply \texttt{fun(x:nat).(plus x x)} to an argument \texttt{(S (S Z))}
by writing \texttt{(fun(x:nat).(plus x x) (S (S Z)))}, as we did in
this example.

\subsection{Definitions}

Most often we write a function expecting it to be called in multiple
places in our code.  We would like to give the function a name, and
then refer to it by that name later.  In \textsc{Guru}, this can be
done with a \texttt{Define}-command. To demonstrate this, add to the
bottom of \texttt{test.g} the following:

\begin{verbatim}
Define double := fun(x:nat).(plus x x).

Interpret (double (S (S Z))).
\end{verbatim}

\noindent The \texttt{Define}-command assigns name \texttt{double} to
the \texttt{fun}-term.  We can then refer to that function by
the name \texttt{double}, as we do in the subsequent
\texttt{Interpret}-command.  If you run \guru\ on \texttt{test.g},
you will see the same result for this \texttt{Interpret}-command
as we had previously: \texttt{(S (S (S (S Z))))}.

\subsection{Multiple arguments}

The syntax for functions with multiple arguments is demonstrated
by this example:

\begin{verbatim}
Define double_plus := fun(x:nat)(y:nat). (plus (double x) (double y)).
\end{verbatim}

\noindent This function is supposed to double each of its two
arguments, and then add them.  The nested application \texttt{(plus
(double x) (double y))} does that.  The \texttt{fun}-term is
written with each argument and its type between parentheses, as this
example shows.  There is a more concise notation when consecutive
arguments have the same type, demonstrated by:

\begin{verbatim}
Define double_plus_a := fun(x y:nat). (plus (double x) (double y)).
\end{verbatim}

\noindent Multiple consecutive arguments can be listed in the same
parenthetical group, followed by a colon, and then their type.

\subsection{Function types}

You can see the classifier that \guru computes for the \texttt{double}
function as follows.  In your \texttt{test.g} file (in your home
directory, beginning with an \texttt{Include}-command to include
\texttt{plus.g}, as above), write the following:

\begin{verbatim}
Define double := fun(x:nat).(plus x x).

Classify double.
\end{verbatim}

\noindent If you (save your file and then) run \guru\ on \texttt{test.g},
it will print

\begin{verbatim}
Fun(x : nat). nat
\end{verbatim}

\noindent This is a \texttt{Fun}-type.  \texttt{Fun}-types classify
\texttt{fun}-term by showing the input names and types, and
the output type.  We can see that \guru\ has computed the (correct)
output type \texttt{nat} for our doubling function.

Earlier it was mentioned that every expression in \guru\ has a
classifier.  You may be curious to see what the classifier for
\texttt{Fun(x : nat). nat} is.  So add the following to your
\texttt{test.g} and re-run \guru\ on it:

\begin{verbatim}
Classify Fun(x : nat). nat.
\end{verbatim}

\noindent You will see the result \texttt{type}.  If you ask \guru\
for the classifier of \texttt{type}, it will tell you \texttt{tkind}.
If you ask for the classifier of \texttt{tkind}, \guru\ will report a
parse error, because \texttt{tkind} is not an expression.  So the
classification hierarchy stops there.  We have the following
classifications (this is not valid \guru\ syntax, but nicely shows the
classification relationships):

\begin{verbatim}
fun(x:nat).(plus x x)  :  Fun(x:nat).nat  :  type  :  tkind
\end{verbatim} 

\subsection{Functions as inputs}

Now that we have seen how to write function types, we can write a
function that takes in a function \texttt{f} of type
\texttt{Fun(x:nat).nat} and applies \texttt{f} twice to an argument
\texttt{a}:

\begin{verbatim}
Define apply_twice := fun(f:Fun(x:nat).nat)(a:nat). (f (f a)).
\end{verbatim}

\noindent There is no new syntax here: we are just writing another
\texttt{fun}-term with arguments \texttt{f} and \texttt{a}.  The
difference from previous examples, of course, is that the type we list
for \texttt{f} is a \texttt{Fun}-type.  An argument to a
\texttt{fun}-term (or listed in a \texttt{Fun}-type) can have any
legal \guru\ type, including, as here, a \texttt{Fun}-type. You can
test out this example like this (although before you run it, try to
figure out what it will compute):

\begin{verbatim}
Interpret (apply_twice double (S (S Z))).
\end{verbatim}

\subsection{Functions as outputs}

Functions can be returned as output from other functions.  This is
actually already possible with functions we have seen above.  For
example, consider the \texttt{plus} function.  Its type, as revealed
by a \texttt{Classify}-command, is 

\begin{verbatim}
Fun(n : nat)(m : nat). nat
\end{verbatim}

\noindent Now try the following:

\begin{verbatim}
Classify (plus (S (S Z))).
\end{verbatim}

\noindent \guru\ will say that the classifier of this expression is:

\begin{verbatim}
Fun(m : nat). nat
\end{verbatim}

\noindent This example shows that we can apply functions to fewer than
all the arguments they accept.  Such an application is called a
\emph{partial application} of the function.  In this case,
\texttt{plus} accepts two arguments, but we can apply it to just the
first argument, in this case \texttt{(S (S Z))}.  The result is a
function that is waiting for the second argument \texttt{m}, and will
then return the result of adding two to m.  This point can be brought
out with the following:

\begin{verbatim}
Define plus2 := (plus (S (S Z))).

Interpret (plus2 (S (S (S Z)))).
\end{verbatim}

\noindent We define the \texttt{plus2} function to be the partial
application of \texttt{plus} to \texttt{(S (S Z))}, and then interpret
the application of \texttt{plus2} to three.  \guru\ will print five
(in unary), as expected.

For another example of using functions as outputs, here is a function
to compose two functions, each of type \texttt{Fun(x:nat).nat}:

\begin{verbatim}
fun(f g : Fun(x:nat).nat). fun(x:nat). (f (g x))
\end{verbatim}

\noindent The inputs to this \texttt{fun}-term are functions \texttt{f} and \texttt{g}.
The body, which computes the output value returned by the function, is

\begin{verbatim}
fun(x:nat). (f (g x))
\end{verbatim}

\noindent This is, of course, a function that takes in input \texttt{x} of type
\texttt{nat}, and returns \texttt{(f (g x))}.  In \guru, what we have written
as the definition of our composition function is equivalent to:

\begin{verbatim}
fun(f g : Fun(x:nat).nat)(x:nat). (f (g x))
\end{verbatim}

\noindent That is, due to partial applications, we can write our
composition function as a function with three arguments: \texttt{f},
\texttt{g}, and \texttt{x}.  We can then just apply it to the first
two, to get the composition.

\subsection{Comments}

This is not a bad place to describe the syntax for comments in \guru.  To
comment out all text to the end of the line, we use \%.  For example:

\begin{verbatim}
Define plus2 := (plus (S (S Z))).  % This text here is in a comment.
\end{verbatim}

\noindent Comments can also be started and stopped by enclosing them
betwee \texttt{\%-} and \texttt{-\%}, as in:

\begin{verbatim}
%- Comments can also be written using
   this syntax. -%
\end{verbatim}

\noindent Comments can be placed anywhere in \guru\ input, including in the
middle of expressions, like this:

\begin{verbatim}
Interpret (plus %- here is a comment -% Z).
\end{verbatim}

\section{Pattern Matching}

Like other functional languages that rely on inductive datatypes,
\guru\ programs can use pattern matching to analyze data by taking it
apart into its subdata.  To demonstrate this, we will write a simple
function to test whether a \texttt{nat} is zero (\texttt{Z}) or not.
For this, we need the definition of booleans, provided in
\texttt{guru-lang/lib/bool.g}.  This file is included by
\texttt{nat.g} (included by \texttt{plus.g}) is so we do not need to
include \texttt{bool.g} explicitly.  It is worth noting that it is not
an error in \guru\ to include a file multiple times: \guru\ keeps
track of which files have been included (by their full pathnames), and
ignores requests after the first one to include the file.  So suppose
our \texttt{test.g} file in our home directory starts off as above:

\begin{verbatim}
Include "guru-lang/lib/plus.g".
\end{verbatim}

\noindent This will pull in the declaration of the booleans, which is:

\begin{verbatim}
Inductive bool : type :=
  ff : bool
| tt : bool.
\end{verbatim}

\noindent Just as for the declaration of \texttt{nat} above, this
\texttt{Inductive}-command instructs \guru\ to add constructors
\texttt{tt} (for true) and \texttt{ff} (for false), both of type
\texttt{bool}.  Now we can define the \texttt{iszero} function as
follows:

\begin{verbatim}
Define iszero := 
  fun(x:nat). 
    match x with 
      Z => tt 
    | S x' => ff
    end.
\end{verbatim}

\noindent Let us walk through this definition.  First, we see it is
written across several lines, with changing indentation.  Whitespace
in \guru, as in most sensible languages, has no semantic impact.  So
the indentation and line breaks are just (intended) to make it easier
to read the code.  It would have the same meaning if we wrote it all
on one line, like this:

\begin{verbatim}
Define iszero := fun(x:nat). match x with Z => tt | S x' => ff end.
\end{verbatim}

\noindent To return to the code: we have a \texttt{Define}-command,
just as we have seen above.  We are defining \texttt{iszero} to be a
certain \texttt{fun}-term.  This \texttt{fun}-term takes in input
\texttt{x} of type \texttt{nat}, and then it matches on \texttt{x}.
Here is where the pattern matching comes into play.  

We have ``\texttt{match x with}''.  In this first part of the
\texttt{match}-term, we are saying we want to pattern match on
\texttt{x}.  We are allowed to match on anything whose type is an
inductive type (i.e., declared with an \texttt{Inductive}-command).
We cannot match on functions, for example, because they have
\texttt{Fun}-types, which are not inductive.  The term we are matching
on is called the \emph{scrutinee} (because the \texttt{match}-term is
scrutinizing -- i.e., analyzing -- it).  

Next come the \texttt{match}-clauses, separated by a bar (``\texttt{|}''):

\begin{verbatim}
      Z => tt 
    | S x' => ff
\end{verbatim}

\noindent We have one clause for each constructor of the scrutinee's
type.  The scrutinee (\texttt{x} in ``\texttt{match x with}'') has
type \texttt{nat}, which has constructors \texttt{Z} and \texttt{S},
so we have one clause for each of those constructors.  It is required
in \guru\ to list the clauses in the same order as the constructors
were declared in the \texttt{Inductive}-command which declared the
datatype.  Our declaration of \texttt{nat} (back in
Section~\ref{ch2:natguru}) lists \texttt{Z} first and then \texttt{S},
so that explains the ordering of the \texttt{match}-clauses here.

Each \texttt{match}-case starts out with a pattern for the
corresponding constructor.  The pattern starts with the constructor,
and then lists different variables for each of the constructor's
arguments.  So we have the patterns \texttt{Z} and \texttt{S x'}.  The
first pattern has no variables, since \texttt{Z} takes no arguments.
The second pattern has the single variable \texttt{x'}, for the sole
argument of \texttt{S}.  These variables are called pattern variables.
They are declared by the pattern, and their scope is the rest of the
\texttt{match}-clause.

After the pattern, each \texttt{match}-clause has ``\texttt{=>}'', and
then its \emph{body}.  This is similar to the body of a
\texttt{fun}-term: it gives the code to compute the value returned by
the function.  For our \texttt{iszero} function, we return \texttt{tt}
in the zero (\texttt{Z}) case, and \texttt{ff} in the successor
(\texttt{S}) case.  If we then run the following example, we will get
the expected value of \texttt{tt}:

\begin{verbatim}
Interpret (iszero Z).
\end{verbatim}

\section{Recursive Functions}

We are finally in a position now to see how to define recursive
functions.  \guru\ does not have iterative looping constructs like
\texttt{while}- or \texttt{for}-loops.  Instead, all looping is done
by recursion.  Here is the code for \texttt{plus}, taken from
\texttt{guru-lang/lib/plus.g}:

\begin{verbatim}
  fun plus(n m : nat) : nat.
    match n with
      Z => m
    | S n' => (S (plus n' m))
    end
\end{verbatim}

\noindent This is a recursive \texttt{fun}-term.  There are two main
differences from the non-recursive \texttt{fun}-terms we have seen
above.  First and foremost, the ``\texttt{fun}'' keyword is followed
by a name for the recursive function.  This name can be used in the
body of the function to make a recursive call.  We see it used in the
second \texttt{match}-clause.  We will walk through the
\texttt{match}-clauses in just a moment, but before that we note the
second distinctive feature of a recursive \texttt{fun}-term: after the
argument list (``\texttt{(n m : nat)}''), there is colon and then the
return type of the \texttt{fun}-term is listed (``\texttt{ : nat}'').
Since \texttt{plus} returns a \texttt{nat}, that is the return type.
The reason \guru\ requires us to list the return type here for a
recursive \texttt{fun}-term is that it makes it much easier to type
check the term.  Wherever \texttt{plus} is called in the body of the
function, we know exactly what its input types and output type are.
If \guru\ allowed us to omit the output type here at the start of the
\texttt{fun}-term, then the type checker would not know the type of
the value that is being computed by the recursive call to
\texttt{plus} in the second \texttt{match}-clause.

Syntactically, there is nothing else new in the code.  But let us try
to understand how it manages to add two unary natural numbers.  The
code is based on the following two mathematical equations:
\begin{eqnarray*}
0+ m & = & m \\
(1+n')+m & = & 1+(n'+m)
\end{eqnarray*}

\noindent These are certainly true statements about addition.  But
how do they relate to the \texttt{fun}-term written above?  Let us
see how to transform them step by step into that \texttt{fun}-term.
First, we should recognize that $0$ and $1+x$ are just different
notation for zero and successor of $x$.  If we use the notation we
have used in \guru\ so far for these, the mathematical equations
turn into:
\begin{eqnarray*}
\texttt{Z}+ m & = & m \\
(\texttt{S}\ n')+m & = & (\texttt{S}\ (n'+m))
\end{eqnarray*}

\noindent Now, we do not have infix notation in \guru\ for functions,
so let us replace the infix $+$ symbol with a prefix \texttt{plus}:

\begin{eqnarray*}
\texttt{(plus Z m)} & = & m \\
\texttt{(plus (S n') m)} & = & \texttt{(S (plus n' m))}
\end{eqnarray*}

\noindent Now look at the right hand sides of the equations we have
derived by this simple syntactic transformation.  They are exactly the
same as the bodies of the \texttt{match}-clauses for the recursive
\texttt{fun}-term for \texttt{plus}.  The final connection can be made
between these equations and that \texttt{fun}-term by observing that
the equations are performing a case split on the first argument
(called \texttt{n} in the \texttt{fun}-term): either it is \texttt{Z},
or else it is \texttt{S n'} for some \texttt{n'}.  This case split is
done in the \texttt{fun}-term using pattern matching.  The final point
to observe is that where we use \texttt{plus} on the right hand side
of the second equation, we are making a recursive call to
\texttt{plus}.  This corresponds to the recursive call in the
\texttt{fun}-term.  In fact, we can observe that with each recursive
call, the first argument gets smaller.  It is \texttt{(S n')} to start
with, and then decreases to \texttt{n'}, which is \emph{structurally
smaller} than \texttt{(S n')}.  Structurally smaller means that
\texttt{n'} is actually subdata of \texttt{(S n')}.  While we do not
need this observation now, it will be critical when reasoning with
\texttt{plus}, since it implies that \texttt{plus} is a \emph{total}
function.  That is, \texttt{plus} is guaranteed to terminate with a
value for all inputs we give it.

\section{Summary}

In this chapter, we have seen the four basic programming features of
\guru, in the setting of monomorphic programming:
\begin{itemize}
\item inductive datatypes, like \texttt{nat} for unary natural
numbers, which has \emph{constructors} \texttt{Z} for zero and
\texttt{S} for the successor of a number;
\item applications like \texttt{(S Z)} of a function (which happens to be a constructor) \texttt{S} to argument \texttt{Z},
and like \texttt{(plus x y)} for applying the function \texttt{plus} to arguments \texttt{x} and \texttt{y};
\item non-recursive, like the doubling function \texttt{fun(x:nat).(plus x x)}, and recursive ones, like \texttt{plus}; and
\item pattern matching, which allows us to analyze (i.e., take apart)
a piece of data (the \emph{scrutinee}) into its subdata.
\end{itemize}

 \noindent We have also seen how to run \guru\ on simple examples,
drawing on code from the \guru\ standard library (like the code for
\texttt{plus}).

\section{Exercises}



\bibliographystyle{plain}
\bibliography{the-bib}

\end{document}
